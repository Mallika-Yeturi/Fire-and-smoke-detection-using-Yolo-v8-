{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "di-F67S9oOl4"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FYYPebgBoZRA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomObjectDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomObjectDetectionModel, self).__init__()\n",
    "        # Define convolutional layers for feature extraction\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Define fully connected layers for classification and bounding box regression\n",
    "        self.fc1 = nn.Linear(256 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.fc3 = nn.Linear(512, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation and max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "\n",
    "        # Flatten the feature maps\n",
    "        x = x.view(-1, 256 * 28 * 28)\n",
    "\n",
    "        # Apply fully connected layers for classification\n",
    "        x = F.relu(self.fc1(x))\n",
    "        cls_output = F.softmax(self.fc2(x), dim=1)  # Apply softmax activation\n",
    "\n",
    "        # Apply fully connected layers for bounding box regression\n",
    "        reg_output = self.fc3(x)\n",
    "\n",
    "        return cls_output, reg_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hGAOKgJGoe0I"
   },
   "outputs": [],
   "source": [
    "# Define input shape of images\n",
    "input_shape = (228, 228)\n",
    "num_classes = 3  # Number of output classes: fire and smoke\n",
    "\n",
    "# custom object detection model\n",
    "object_detection_model = CustomObjectDetectionModel(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sXgRAqI9xqg",
    "outputId": "056f8daf-0628-4aef-fd9c-ff8bc7adde52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomObjectDetectionModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=200704, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(object_detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vxEHEAnWonWY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, image_ext=\".jpg\", label_ext=\".txt\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_ext = image_ext\n",
    "        self.label_ext = label_ext\n",
    "        self.transform = transform\n",
    "        print(root_dir)\n",
    "        self.image_files = [file for file in os.listdir(root_dir + \"/images\") if file.endswith(image_ext)]\n",
    "        self.label_files = [file for file in os.listdir(root_dir+ \"/labels\") if file.endswith(label_ext)]\n",
    "        print(\"Number of image files:\", len(self.image_files))\n",
    "        print(\"Number of label files:\", len(self.label_files))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir+ \"/images\", self.image_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load corresponding label file based on image file\n",
    "        label_name = os.path.join(self.root_dir+ \"/labels\", self.label_files[idx])\n",
    "        # Implement logic to load and preprocess label data\n",
    "        with open(label_name, 'r') as file:\n",
    "            label_data = file.read().strip()  # Read and preprocess label data as needed\n",
    "\n",
    "\n",
    "        return image, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCBb500AIaYS",
    "outputId": "dc39e923-709c-4aac-faf4-15dce4186410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/YOLOv8-Fire-and-Smoke-Detection/datasets/fire-8/train\n",
      "Number of image files: 877\n",
      "Number of label files: 877\n",
      "/content/YOLOv8-Fire-and-Smoke-Detection/datasets/fire-8/test\n",
      "Number of image files: 55\n",
      "Number of label files: 55\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_shape[:2]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define training dataset\n",
    "train_dataset = CustomDataset(root_dir='/content/YOLOv8-Fire-and-Smoke-Detection/datasets/fire-8/train',\n",
    "                              image_ext=\".jpg\",\n",
    "                              label_ext=\".txt\",\n",
    "                              transform=data_transforms)\n",
    "\n",
    "# Define data loaders for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define testing dataset\n",
    "test_dataset = CustomDataset(root_dir='/content/YOLOv8-Fire-and-Smoke-Detection/datasets/fire-8/test',\n",
    "                             image_ext=\".jpg\",\n",
    "                             label_ext=\".txt\",\n",
    "                             transform=data_transforms)\n",
    "\n",
    "# Define data loader for testing\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "atucA43wuTfm"
   },
   "outputs": [],
   "source": [
    "#loss function and optimizer\n",
    "optimizer = optim.Adam(object_detection_model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kf0pEfpdM4jG",
    "outputId": "6b3a3446-2a34-4ae9-fca4-0d5cacbc13e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjqPTrwLc1R4",
    "outputId": "9df37d9d-15fd-48f9-bcf8-a22e76fbbf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8hH40s8VUiAz"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the classification loss criterion\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the regression loss criterion\n",
    "criterion_reg = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EA9rDo3mQCF",
    "outputId": "4803dd8b-c087-4130-db84-3c40eee5130b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Batch [27/27]: : 28it [02:06,  4.53s/it]\n",
      "Epoch [1/100], Loss: 0.9998\n",
      "Epoch [2/100], Batch [27/27]: : 28it [02:02,  4.39s/it]\n",
      "Epoch [2/100], Loss: 0.9935\n",
      "Epoch [3/100], Batch [27/27]: : 28it [01:55,  4.12s/it]\n",
      "Epoch [3/100], Loss: 0.9935\n",
      "Epoch [4/100], Batch [27/27]: : 28it [01:51,  3.99s/it]\n",
      "Epoch [4/100], Loss: 0.9935\n",
      "Epoch [5/100], Batch [27/27]: : 28it [01:53,  4.05s/it]\n",
      "Epoch [5/100], Loss: 0.9931\n",
      "Epoch [6/100], Batch [27/27]: : 28it [01:59,  4.26s/it]\n",
      "Epoch [6/100], Loss: 0.8799\n",
      "Epoch [7/100], Batch [27/27]: : 28it [01:53,  4.05s/it]\n",
      "Epoch [7/100], Loss: 0.8668\n",
      "Epoch [8/100], Batch [27/27]: : 28it [01:58,  4.24s/it]\n",
      "Epoch [8/100], Loss: 0.8599\n",
      "Epoch [9/100], Batch [27/27]: : 28it [01:53,  4.06s/it]\n",
      "Epoch [9/100], Loss: 0.8578\n",
      "Epoch [10/100], Batch [27/27]: : 28it [01:55,  4.13s/it]\n",
      "Epoch [10/100], Loss: 0.8403\n",
      "Epoch [11/100], Batch [27/27]: : 28it [01:56,  4.14s/it]\n",
      "Epoch [11/100], Loss: 0.8309\n",
      "Epoch [12/100], Batch [27/27]: : 28it [01:49,  3.91s/it]\n",
      "Epoch [12/100], Loss: 0.8309\n",
      "Epoch [13/100], Batch [27/27]: : 28it [01:48,  3.86s/it]\n",
      "Epoch [13/100], Loss: 0.8307\n",
      "Epoch [14/100], Batch [27/27]: : 28it [01:45,  3.77s/it]\n",
      "Epoch [14/100], Loss: 0.8307\n",
      "Epoch [15/100], Batch [27/27]: : 28it [01:41,  3.61s/it]\n",
      "Epoch [15/100], Loss: 0.8307\n",
      "Epoch [16/100], Batch [27/27]: : 28it [01:43,  3.69s/it]\n",
      "Epoch [16/100], Loss: 0.8305\n",
      "Epoch [17/100], Batch [27/27]: : 28it [01:46,  3.81s/it]\n",
      "Epoch [17/100], Loss: 0.8305\n",
      "Epoch [18/100], Batch [27/27]: : 28it [01:46,  3.79s/it]\n",
      "Epoch [18/100], Loss: 0.8305\n",
      "Epoch [19/100], Batch [27/27]: : 28it [01:41,  3.64s/it]\n",
      "Epoch [19/100], Loss: 0.8305\n",
      "Epoch [20/100], Batch [27/27]: : 28it [01:50,  3.95s/it]\n",
      "Epoch [20/100], Loss: 0.8264\n",
      "Epoch [21/100], Batch [27/27]: : 28it [01:58,  4.22s/it]\n",
      "Epoch [21/100], Loss: 0.8264\n",
      "Epoch [22/100], Batch [27/27]: : 28it [02:07,  4.54s/it]\n",
      "Epoch [22/100], Loss: 0.8264\n",
      "Epoch [23/100], Batch [27/27]: : 28it [01:57,  4.21s/it]\n",
      "Epoch [23/100], Loss: 0.8264\n",
      "Epoch [24/100], Batch [27/27]: : 28it [01:48,  3.89s/it]\n",
      "Epoch [24/100], Loss: 0.8245\n",
      "Epoch [25/100], Batch [27/27]: : 28it [01:48,  3.86s/it]\n",
      "Epoch [25/100], Loss: 0.8200\n",
      "Epoch [26/100], Batch [27/27]: : 28it [01:43,  3.69s/it]\n",
      "Epoch [26/100], Loss: 0.8145\n",
      "Epoch [27/100], Batch [27/27]: : 28it [01:50,  3.95s/it]\n",
      "Epoch [27/100], Loss: 0.7843\n",
      "Epoch [28/100], Batch [27/27]: : 28it [01:50,  3.96s/it]\n",
      "Epoch [28/100], Loss: 0.7836\n",
      "Epoch [29/100], Batch [27/27]: : 28it [02:02,  4.37s/it]\n",
      "Epoch [29/100], Loss: 0.7152\n",
      "Epoch [30/100], Batch [27/27]: : 28it [01:55,  4.11s/it]\n",
      "Epoch [30/100], Loss: 0.7122\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "epochs = 30\n",
    "checkpoint_dir = '/content/drive/MyDrive/chk'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint = torch.load(\"/content/drive/MyDrive/chk/object_detection_model_epoch_9.pth\")\n",
    "\n",
    "# Load the model state dictionary\n",
    "object_detection_model.load_state_dict(checkpoint)\n",
    "\n",
    "epoch_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loader_iterator = iter(train_loader)\n",
    "    object_detection_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader_iterator), total=(len(train_loader)-1))\n",
    "\n",
    "    for batch_idx, (inputs, labels_tuple) in progress_bar:\n",
    "        if batch_idx == 27:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cls_output, reg_output = object_detection_model(inputs)\n",
    "\n",
    "        for i in range(len(cls_output)):\n",
    "            label_tensor = labels_tuple[i]\n",
    "\n",
    "            try:\n",
    "                if isinstance(label_tensor, str):\n",
    "                    label_values = label_tensor.split(' ')\n",
    "                else:\n",
    "                    label_values = [str(val.item()) for val in label_tensor.flatten()]\n",
    "\n",
    "                if label_values:\n",
    "                    class_label = int(float(label_values[0]))\n",
    "                    bbox_values = [float(val) for val in label_values[1:] if val != '\\n']\n",
    "\n",
    "                    labels_tensor = torch.tensor([class_label] + bbox_values, dtype=torch.float32)\n",
    "\n",
    "                    cls_loss = criterion_cls(cls_output[i:i+1], torch.tensor([class_label]))\n",
    "                    reg_loss = criterion_reg(reg_output[i:i+1], labels_tensor[1:].unsqueeze(0))\n",
    "\n",
    "                    loss = cls_loss + reg_loss\n",
    "\n",
    "                    loss.backward(retain_graph=True)\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_description(f'Epoch [{epoch + 1}/{epochs}], Batch [{batch_idx + 1}/{(len(train_loader)-1)}]')\n",
    "\n",
    "    epoch_loss = running_loss / (len(train_loader) -1)\n",
    "    epoch_loss_history.append(epoch_loss)\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:  # Save checkpoint and loss history every 20 epochs\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'object_detection_model_epoch_{epoch+1}.pth')\n",
    "        torch.save(object_detection_model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # Save epoch loss history to a file\n",
    "        history_file = os.path.join(checkpoint_dir, f'epoch_loss_history_epoch_{epoch+1}.txt')\n",
    "        with open(history_file, 'w') as file:\n",
    "            for loss in epoch_loss_history:\n",
    "                file.write(f'{loss}\\n')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Save final trained model\n",
    "final_model_path = os.path.join(checkpoint_dir, 'object_detection_model_final.pth')\n",
    "torch.save(object_detection_model.state_dict(), final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDyfaJ6GxtQ2",
    "outputId": "78a53c20-acd7-444d-f9ed-759ecd9275e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n",
      "Precision: 0.2500\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.3333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "object_detection_model.eval()\n",
    "\n",
    "# Lists to store predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "for inputs,labels_tuple in test_loader:\n",
    "  print(inputs.shape)\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for inputs, labels_tuple in test_loader:\n",
    "    # Forward pass\n",
    "    cls_output, _ = object_detection_model(inputs)\n",
    "\n",
    "    # Convert class probabilities to predicted labels\n",
    "    _, predicted = torch.max(cls_output, 1)\n",
    "\n",
    "    # Convert tensor to numpy array and append to the list\n",
    "    all_predictions.extend(predicted.numpy())\n",
    "\n",
    "    # Extract class labels from labels_tuple\n",
    "    labels = [int(label.split()[0]) for label in labels_tuple]\n",
    "\n",
    "    # Append ground truth labels to the list\n",
    "    all_labels.extend(labels)\n",
    "    break\n",
    "\n",
    "# Convert lists to numpy arrays for ease of computation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "labels = all_labels[:8]\n",
    "print(labels.size)\n",
    "print(all_predictions.size)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(labels, all_predictions)\n",
    "precision = precision_score(labels, all_predictions, average='macro')\n",
    "recall = recall_score(labels, all_predictions, average='macro')\n",
    "f1 = f1_score(labels, all_predictions, average='macro')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "lRmC7R5tTywi",
    "outputId": "d1e0b22a-5d82-4122-f3bf-686a876c6561"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define evaluation metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "values = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Plot bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for better visualization\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
